{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"transformations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://HP:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>transformations</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2be5436ded0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map vs flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'world'],\n",
       " ['This', 'is', 'a', 'Spark', 'example'],\n",
       " [\"We're\", 'using', 'map', 'and', 'flatMap']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.parallelize([\n",
    "    \"Hello world\",\n",
    "    \"This is a Spark example\",\n",
    "    \"We're using map and flatMap\"]).map(lambda x : x.split(\" \")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'world',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'Spark',\n",
       " 'example',\n",
       " \"We're\",\n",
       " 'using',\n",
       " 'map',\n",
       " 'and',\n",
       " 'flatMap']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.parallelize([\n",
    "    \"Hello world\",\n",
    "    \"This is a Spark example\",\n",
    "    \"We're using map and flatMap\"]).flatMap(lambda x : x.split(\" \")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduceByKey vs reduce vs countByValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 1), (8, 1), (1, 1), (5, 2), (9, 1), (2, 1), (6, 2), (3, 2), (7, 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduceByKey is a transformation\n",
    "\n",
    "spark.sparkContext.parallelize([1,2,3,4,5,6,7,8,9,3,5,6,7]). \\\n",
    "    map(lambda x  : (x,1)). \\\n",
    "    reduceByKey(lambda x,y : x+y ). \\\n",
    "    collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce is action\n",
    "spark.sparkContext.parallelize([1,2,3,4,5,6,7,8,9,3,5,6,7]). \\\n",
    "        reduce( lambda x,y : x+y)   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 1, 3: 2, 4: 1, 5: 2, 6: 2, 7: 2, 8: 1, 9: 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countByValue is an action\n",
    "spark.sparkContext.parallelize([1,2,3,4,5,6,7,8,9,3,5,6,7]). \\\n",
    "    map(lambda x  : x). \\\n",
    "        countByValue() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduceByKey  vs  groupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"transformations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://HP:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>transformations</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2be55248d10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstore_rdd = spark.sparkContext.textFile(\"hdfs://localhost:9000/user/tkm/data/superstore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,CA-2016-152156,11/8/2016,11/11/2016,Second Class,CG-12520,Claire Gute,Consumer,United States,Henderson,Kentucky,42420,South,FUR-BO-10001798,Furniture,Bookcases,Bush Somerset Collection Bookcase,261.96,2,0,41.9136',\n",
       " '2,CA-2016-152156,11/8/2016,11/11/2016,Second Class,CG-12520,Claire Gute,Consumer,United States,Henderson,Kentucky,42420,South,FUR-CH-10000454,Furniture,Chairs,\"Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back\",731.94,3,0,219.582',\n",
       " '3,CA-2016-138688,6/12/2016,6/16/2016,Second Class,DV-13045,Darrin Van Huff,Corporate,United States,Los Angeles,California,90036,West,OFF-LA-10000240,Office Supplies,Labels,Self-Adhesive Address Labels for Typewriters by Universal,14.62,2,0,6.8714',\n",
       " \"4,US-2015-108966,10/11/2015,10/18/2015,Standard Class,SO-20335,Sean O'Donnell,Consumer,United States,Fort Lauderdale,Florida,33311,South,FUR-TA-10000577,Furniture,Tables,Bretford CR4500 Series Slim Rectangular Table,957.5775,5,0.45,-383.031\",\n",
       " \"5,US-2015-108966,10/11/2015,10/18/2015,Standard Class,SO-20335,Sean O'Donnell,Consumer,United States,Fort Lauderdale,Florida,33311,South,OFF-ST-10000760,Office Supplies,Storage,Eldon Fold 'N Roll Cart System,22.368,2,0.2,2.5164\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superstore_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_rdd = superstore_rdd.map(lambda x : (x.split(\",\")[10],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kentucky', 1),\n",
       " ('Kentucky', 1),\n",
       " ('California', 1),\n",
       " ('Florida', 1),\n",
       " ('Florida', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_rdd = country_rdd.reduceByKey(lambda x,y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('North Carolina', 249),\n",
       " ('Washington', 506),\n",
       " ('Wisconsin', 110),\n",
       " ('Nebraska', 38),\n",
       " ('Illinois', 492),\n",
       " ('Indiana', 149),\n",
       " ('New York', 1128),\n",
       " ('Virginia', 224),\n",
       " ('Tennessee', 183),\n",
       " ('Alabama', 61),\n",
       " ('Oregon', 124),\n",
       " ('Colorado', 182),\n",
       " ('Missouri', 66),\n",
       " ('Oklahoma', 66),\n",
       " ('Louisiana', 42),\n",
       " ('Connecticut', 82),\n",
       " ('New Jersey', 130),\n",
       " ('Nevada', 39),\n",
       " ('Mississippi', 53),\n",
       " ('New Hampshire', 27),\n",
       " ('Kansas', 24),\n",
       " ('South Dakota', 12),\n",
       " ('Idaho', 21),\n",
       " ('Wyoming', 1),\n",
       " ('Kentucky', 139),\n",
       " ('California', 2001),\n",
       " ('Florida', 383),\n",
       " ('Texas', 985),\n",
       " ('Utah', 53),\n",
       " ('Pennsylvania', 587),\n",
       " ('Minnesota', 89),\n",
       " ('Michigan', 255),\n",
       " ('Delaware', 96),\n",
       " ('Arizona', 224),\n",
       " ('South Carolina', 42),\n",
       " ('Iowa', 30),\n",
       " ('Ohio', 469),\n",
       " ('New Mexico', 37),\n",
       " ('Massachusetts', 135),\n",
       " ('Georgia', 184),\n",
       " ('Rhode Island', 56),\n",
       " ('Arkansas', 60),\n",
       " ('Montana', 15),\n",
       " ('Maryland', 105),\n",
       " ('District of Columbia', 10),\n",
       " ('Vermont', 11),\n",
       " ('Maine', 8),\n",
       " ('North Dakota', 7),\n",
       " ('West Virginia', 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('North Carolina', 249),\n",
       " ('Washington', 506),\n",
       " ('Wisconsin', 110),\n",
       " ('Nebraska', 38),\n",
       " ('Illinois', 492),\n",
       " ('Indiana', 149),\n",
       " ('New York', 1128),\n",
       " ('Virginia', 224),\n",
       " ('Tennessee', 183),\n",
       " ('Alabama', 61),\n",
       " ('Oregon', 124),\n",
       " ('Colorado', 182),\n",
       " ('Missouri', 66),\n",
       " ('Oklahoma', 66),\n",
       " ('Louisiana', 42),\n",
       " ('Connecticut', 82),\n",
       " ('New Jersey', 130),\n",
       " ('Nevada', 39),\n",
       " ('Mississippi', 53),\n",
       " ('New Hampshire', 27),\n",
       " ('Kansas', 24),\n",
       " ('South Dakota', 12),\n",
       " ('Idaho', 21),\n",
       " ('Wyoming', 1),\n",
       " ('Kentucky', 139),\n",
       " ('California', 2001),\n",
       " ('Florida', 383),\n",
       " ('Texas', 985),\n",
       " ('Utah', 53),\n",
       " ('Pennsylvania', 587),\n",
       " ('Minnesota', 89),\n",
       " ('Michigan', 255),\n",
       " ('Delaware', 96),\n",
       " ('Arizona', 224),\n",
       " ('South Carolina', 42),\n",
       " ('Iowa', 30),\n",
       " ('Ohio', 469),\n",
       " ('New Mexico', 37),\n",
       " ('Massachusetts', 135),\n",
       " ('Georgia', 184),\n",
       " ('Rhode Island', 56),\n",
       " ('Arkansas', 60),\n",
       " ('Montana', 15),\n",
       " ('Maryland', 105),\n",
       " ('District of Columbia', 10),\n",
       " ('Vermont', 11),\n",
       " ('Maine', 8),\n",
       " ('North Dakota', 7),\n",
       " ('West Virginia', 4)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark1 = SparkSession.builder.appName(\"reducebykey\").getOrCreate()\n",
    "\n",
    "superstore_rdd = spark1.sparkContext.textFile(\"hdfs://localhost:9000/user/tkm/data/superstore.csv\")\n",
    "\n",
    "country_rdd = superstore_rdd.map(lambda x : (x.split(\",\")[10],1))\n",
    "\n",
    "reduced_rdd = country_rdd.reduceByKey(lambda x,y : x+y)\n",
    "\n",
    "reduced_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('North Carolina', 249),\n",
       " ('Washington', 506),\n",
       " ('Wisconsin', 110),\n",
       " ('Nebraska', 38),\n",
       " ('Illinois', 492),\n",
       " ('Indiana', 149),\n",
       " ('New York', 1128),\n",
       " ('Virginia', 224),\n",
       " ('Tennessee', 183),\n",
       " ('Alabama', 61),\n",
       " ('Oregon', 124),\n",
       " ('Colorado', 182),\n",
       " ('Missouri', 66),\n",
       " ('Oklahoma', 66),\n",
       " ('Louisiana', 42),\n",
       " ('Connecticut', 82),\n",
       " ('New Jersey', 130),\n",
       " ('Nevada', 39),\n",
       " ('Mississippi', 53),\n",
       " ('New Hampshire', 27),\n",
       " ('Kansas', 24),\n",
       " ('South Dakota', 12),\n",
       " ('Idaho', 21),\n",
       " ('Wyoming', 1),\n",
       " ('Kentucky', 139),\n",
       " ('California', 2001),\n",
       " ('Florida', 383),\n",
       " ('Texas', 985),\n",
       " ('Utah', 53),\n",
       " ('Pennsylvania', 587),\n",
       " ('Minnesota', 89),\n",
       " ('Michigan', 255),\n",
       " ('Delaware', 96),\n",
       " ('Arizona', 224),\n",
       " ('South Carolina', 42),\n",
       " ('Iowa', 30),\n",
       " ('Ohio', 469),\n",
       " ('New Mexico', 37),\n",
       " ('Massachusetts', 135),\n",
       " ('Georgia', 184),\n",
       " ('Rhode Island', 56),\n",
       " ('Arkansas', 60),\n",
       " ('Montana', 15),\n",
       " ('Maryland', 105),\n",
       " ('District of Columbia', 10),\n",
       " ('Vermont', 11),\n",
       " ('Maine', 8),\n",
       " ('North Dakota', 7),\n",
       " ('West Virginia', 4)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark2 = SparkSession.builder.appName(\"groupbykey\").getOrCreate()\n",
    "\n",
    "superstore_rdd = spark2.sparkContext.textFile(\"hdfs://localhost:9000/user/tkm/data/superstore.csv\")\n",
    "\n",
    "country_rdd = superstore_rdd.map(lambda x : (x.split(\",\")[10] , x.split(\",\")[17]))\n",
    "\n",
    "grouped_rdd = country_rdd.groupByKey()\n",
    "\n",
    "result_rdd = grouped_rdd.map(lambda x : (x[0] , len(x[1])))\n",
    "\n",
    "result_rdd.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

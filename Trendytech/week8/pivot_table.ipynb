{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"pivot\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data = [(\"DEBUG\",\"2014-6-22 21:30:49\"),\n",
    "(\"WARN\",\"2013-12-6 17:54:15\"),\n",
    "(\"DEBUG\",\"2017-1-12 10:47:02\"),\n",
    "(\"DEBUG\",\"2016-6-25 11:06:42\"),\n",
    "(\"ERROR\",\"2015-6-28 19:25:05\"),\n",
    "(\"DEBUG\",\"2012-6-24 01:06:37\"),\n",
    "(\"INFO\",\"2014-12-9 09:53:54\"),\n",
    "(\"DEBUG\",\"2015-11-8 19:20:08\"),\n",
    "(\"INFO\",\"2017-12-21 18:34:18\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df = spark.createDataFrame(logs_data).toDF(\"loglevel\",\"logtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|   DEBUG| 2014-6-22 21:30:49|\n",
      "|    WARN| 2013-12-6 17:54:15|\n",
      "|   DEBUG| 2017-1-12 10:47:02|\n",
      "|   DEBUG| 2016-6-25 11:06:42|\n",
      "|   ERROR| 2015-6-28 19:25:05|\n",
      "|   DEBUG| 2012-6-24 01:06:37|\n",
      "|    INFO| 2014-12-9 09:53:54|\n",
      "|   DEBUG| 2015-11-8 19:20:08|\n",
      "|    INFO|2017-12-21 18:34:18|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = logs_df.withColumn(\"logtime\", to_timestamp(\"logtime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|loglevel|month|\n",
      "+--------+-----+\n",
      "|   DEBUG|  Jun|\n",
      "|    WARN|  Dec|\n",
      "|   DEBUG|  Jan|\n",
      "|   DEBUG|  Jun|\n",
      "|   ERROR|  Jun|\n",
      "|   DEBUG|  Jun|\n",
      "|    INFO|  Dec|\n",
      "|   DEBUG|  Nov|\n",
      "|    INFO|  Dec|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"loglevel\",date_format(\"logtime\",\"MMM\").alias(\"month\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------------+\n",
      "|loglevel|month|total_occurance|\n",
      "+--------+-----+---------------+\n",
      "|   DEBUG|  Jan|              1|\n",
      "|   DEBUG|  Jun|              3|\n",
      "|   ERROR|  Jun|              1|\n",
      "|   DEBUG|  Nov|              1|\n",
      "|    WARN|  Dec|              1|\n",
      "|    INFO|  Dec|              2|\n",
      "+--------+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = log_df.select(\"loglevel\",\n",
    "                    date_format(\"logtime\",\"MMM\").alias(\"month\"),\n",
    "                    month(\"logtime\").alias(\"month_number\")) \n",
    "df2 = df1.groupBy(\"loglevel\",\"month\",\"month_number\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\",\"total_occurance\") \\\n",
    "        .orderBy(\"month_number\")\n",
    "df2.drop(\"month_number\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.createOrReplaceTempView(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------+---------------+\n",
      "|   month|month_number|loglevel|total_occurance|\n",
      "+--------+------------+--------+---------------+\n",
      "| January|          01|   DEBUG|              1|\n",
      "|    June|          06|   DEBUG|              3|\n",
      "|    June|          06|   ERROR|              1|\n",
      "|November|          11|   DEBUG|              1|\n",
      "|December|          12|    INFO|              2|\n",
      "|December|          12|    WARN|              1|\n",
      "+--------+------------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = spark.sql(\"\"\"\n",
    "                    select \n",
    "                    date_format(logtime ,\"MMMM\") as month,\n",
    "                    first(date_format(logtime ,\"MM\")) as month_number,\n",
    "                    loglevel,\n",
    "                    count(*) as total_occurance\n",
    "                    from logs\n",
    "                    group by month,loglevel\n",
    "                    order by month_number asc\n",
    "                    \"\"\")\n",
    "\n",
    "results_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+\n",
      "|   month|loglevel|total_occurance|\n",
      "+--------+--------+---------------+\n",
      "| January|   DEBUG|              1|\n",
      "|    June|   DEBUG|              3|\n",
      "|    June|   ERROR|              1|\n",
      "|November|   DEBUG|              1|\n",
      "|December|    INFO|              2|\n",
      "|December|    WARN|              1|\n",
      "+--------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = results_df.drop(\"month_number\")\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = log_df.select(\"loglevel\",\n",
    "                    date_format(\"logtime\",\"MMM\").alias(\"month\"),\n",
    "                    date_format(\"logtime\",\"MM\").alias(\"month_number\")) \n",
    "df2 = df1.groupBy(\"loglevel\",\"month\",\"month_number\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\",\"total_occurance\") \\\n",
    "        .orderBy(\"month_number\")\n",
    "df3 = df2.drop(\"month_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = log_df.select(\"loglevel\",\n",
    "                    date_format(\"logtime\",\"MMM\").alias(\"month\"),\n",
    "                    month(\"logtime\").alias(\"month_number\")) \n",
    "df2 = df1.groupBy(\"loglevel\",\"month\",\"month_number\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\",\"total_occurance\") \\\n",
    "        .orderBy(\"month_number\")\n",
    "df3 = df2.drop(\"month_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------------+\n",
      "|loglevel|month|total_occurance|\n",
      "+--------+-----+---------------+\n",
      "|   DEBUG|  Jan|              1|\n",
      "|   DEBUG|  Jun|              3|\n",
      "|   ERROR|  Jun|              1|\n",
      "|   DEBUG|  Nov|              1|\n",
      "|    WARN|  Dec|              1|\n",
      "|    INFO|  Dec|              2|\n",
      "+--------+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+----+----+\n",
      "|loglevel| Dec| Jan| Jun| Nov|\n",
      "+--------+----+----+----+----+\n",
      "|    INFO|   2|null|null|null|\n",
      "|   ERROR|null|null|   1|null|\n",
      "|    WARN|   1|null|null|null|\n",
      "|   DEBUG|null|   1|   3|   1|\n",
      "+--------+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.groupBy(\"loglevel\").pivot(\"month\").sum(\"total_occurance\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|   DEBUG|2014-06-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-12-21 18:34:18|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+----+--------+\n",
      "|loglevel|December|January|June|November|\n",
      "+--------+--------+-------+----+--------+\n",
      "|    INFO|       2|   null|null|    null|\n",
      "|   ERROR|    null|   null|   1|    null|\n",
      "|    WARN|       1|   null|null|    null|\n",
      "|   DEBUG|    null|      1|   3|       1|\n",
      "+--------+--------+-------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"loglevel\",date_format(\"logtime\" , \"MMMM\").alias(\"month_name\")) \\\n",
    ".groupBy(\"loglevel\") \\\n",
    ".pivot(\"month_name\") \\\n",
    ".count() \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+----+----+\n",
      "|loglevel|  01|  06|  11|  12|\n",
      "+--------+----+----+----+----+\n",
      "|    INFO|null|null|null|   2|\n",
      "|   ERROR|null|   1|null|null|\n",
      "|    WARN|null|null|null|   1|\n",
      "|   DEBUG|   1|   3|   1|null|\n",
      "+--------+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"loglevel\",date_format(\"logtime\" , \"MM\").alias(\"month_number\")) \\\n",
    ".groupBy(\"loglevel\") \\\n",
    ".pivot(\"month_number\") \\\n",
    ".count() \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|   DEBUG|2014-06-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-12-21 18:34:18|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from logs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+----+--------+\n",
      "|loglevel|December|January|June|November|\n",
      "+--------+--------+-------+----+--------+\n",
      "|    INFO|       2|   null|null|    null|\n",
      "|   ERROR|    null|   null|   1|    null|\n",
      "|    WARN|       1|   null|null|    null|\n",
      "|   DEBUG|    null|      1|   3|       1|\n",
      "+--------+--------+-------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel,\n",
    "          date_format(logtime , \"MMMM\") as month_name\n",
    "          from logs\"\"\") \\\n",
    "            .groupBy(\"loglevel\") \\\n",
    "            .pivot(\"month_name\") \\\n",
    "            .count() \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+----+----+\n",
      "|loglevel|  01|  06|  11|  12|\n",
      "+--------+----+----+----+----+\n",
      "|    INFO|null|null|null|   2|\n",
      "|   ERROR|null|   1|null|null|\n",
      "|    WARN|null|null|null|   1|\n",
      "|   DEBUG|   1|   3|   1|null|\n",
      "+--------+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel,\n",
    "          date_format(logtime , \"MM\") as month_number\n",
    "          from logs\"\"\") \\\n",
    "            .groupBy(\"loglevel\") \\\n",
    "            .pivot(\"month_number\") \\\n",
    "            .count() \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list=[\"January\",\"June\",\"November\",\"December\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----+--------+--------+\n",
      "|loglevel|January|June|November|December|\n",
      "+--------+-------+----+--------+--------+\n",
      "|    INFO|   null|null|    null|       2|\n",
      "|   ERROR|   null|   1|    null|    null|\n",
      "|    WARN|   null|null|    null|       1|\n",
      "|   DEBUG|      1|   3|       1|    null|\n",
      "+--------+-------+----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"loglevel\",date_format(\"logtime\" , \"MMMM\").alias(\"month_name\")) \\\n",
    ".groupBy(\"loglevel\") \\\n",
    ".pivot(\"month_name\",month_list) \\\n",
    ".count() \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----+--------+--------+\n",
      "|loglevel|January|June|November|December|\n",
      "+--------+-------+----+--------+--------+\n",
      "|    INFO|   null|null|    null|       2|\n",
      "|   ERROR|   null|   1|    null|    null|\n",
      "|    WARN|   null|null|    null|       1|\n",
      "|   DEBUG|      1|   3|       1|    null|\n",
      "+--------+-------+----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel,\n",
    "          date_format(logtime , \"MMMM\") as month_name\n",
    "          from logs\"\"\") \\\n",
    "            .groupBy(\"loglevel\") \\\n",
    "            .pivot(\"month_name\",month_list) \\\n",
    "            .count() \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

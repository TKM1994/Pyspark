{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql\n",
    "#spark.table\n",
    "#spark.read\n",
    "#spark.range\n",
    "#spark.createDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"dataFrame_Creation_Ways\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### first way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(\"hdfs://localhost:9000/user/tkm/data/orders.csv\",header = \"true\",inferSchema=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+-------+\n",
      "|_c0|order_id|      date|customer_id| status|\n",
      "+---+--------+----------+-----------+-------+\n",
      "|  0|       1|09/11/2020|       3371| CLOSED|\n",
      "|  1|       2|12/01/2020|       3902|PENDING|\n",
      "+---+--------+----------+-----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### second way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |    order|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"select * from order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+-------+\n",
      "|_c0|order_id|      date|customer_id| status|\n",
      "+---+--------+----------+-----------+-------+\n",
      "|  0|       1|09/11/2020|       3371| CLOSED|\n",
      "|  1|       2|12/01/2020|       3902|PENDING|\n",
      "+---+--------+----------+-----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### third way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.table(\"order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+-------+\n",
      "|_c0|order_id|      date|customer_id| status|\n",
      "+---+--------+----------+-----------+-------+\n",
      "|  0|       1|09/11/2020|       3371| CLOSED|\n",
      "|  1|       2|12/01/2020|       3902|PENDING|\n",
      "+---+--------+----------+-----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### fourth way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.range(5)\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.range(1,8)\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  3|\n",
      "|  5|\n",
      "|  7|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.range(1,8,2)\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### fifth way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [\n",
    "(1,'2013-07-25',11599,'CLOSED'),\n",
    "(2,'2013-07-25',256,'PENDING_PAYMENT'),\n",
    "(3,'2013-07-25',12111,'COMPLETE'),\n",
    "(4,'2013-07-25',8827,'CLOSED'),\n",
    "(6,'2013-07-25',7130,'COMPLETE'),\n",
    "(7,'2013-07-25',4530,'COMPLETE'),\n",
    "(8,'2013-07-25',2911,'PROCESSING'),\n",
    "(9,'2013-07-25',5657,'PENDING_PAYMENT'),\n",
    "(10,'2013-07-25',5648,'PENDING_PAYMENT')\n",
    "]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+---------------+\n",
      "| _1|        _2|   _3|             _4|\n",
      "+---+----------+-----+---------------+\n",
      "|  1|2013-07-25|11599|         CLOSED|\n",
      "|  2|2013-07-25|  256|PENDING_PAYMENT|\n",
      "|  3|2013-07-25|12111|       COMPLETE|\n",
      "|  4|2013-07-25| 8827|         CLOSED|\n",
      "|  6|2013-07-25| 7130|       COMPLETE|\n",
      "|  7|2013-07-25| 4530|       COMPLETE|\n",
      "|  8|2013-07-25| 2911|     PROCESSING|\n",
      "|  9|2013-07-25| 5657|PENDING_PAYMENT|\n",
      "| 10|2013-07-25| 5648|PENDING_PAYMENT|\n",
      "+---+----------+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = spark.createDataFrame(ls)\n",
    "df_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      " |-- _4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------------+\n",
      "|orderid| orderdate|customerid|    orderstatus|\n",
      "+-------+----------+----------+---------------+\n",
      "|      1|2013-07-25|     11599|         CLOSED|\n",
      "|      2|2013-07-25|       256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25|     12111|       COMPLETE|\n",
      "|      4|2013-07-25|      8827|         CLOSED|\n",
      "|      6|2013-07-25|      7130|       COMPLETE|\n",
      "|      7|2013-07-25|      4530|       COMPLETE|\n",
      "|      8|2013-07-25|      2911|     PROCESSING|\n",
      "|      9|2013-07-25|      5657|PENDING_PAYMENT|\n",
      "|     10|2013-07-25|      5648|PENDING_PAYMENT|\n",
      "+-------+----------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_column = df_raw.toDF(\"orderid\",\"orderdate\",\"customerid\",\"orderstatus\")\n",
    "df_column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderid: long (nullable = true)\n",
      " |-- orderdate: string (nullable = true)\n",
      " |-- customerid: long (nullable = true)\n",
      " |-- orderstatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_column.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|2013-07-25|      11599|         CLOSED|\n",
      "|       2|2013-07-25|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|      12111|       COMPLETE|\n",
      "|       4|2013-07-25|       8827|         CLOSED|\n",
      "|       6|2013-07-25|       7130|       COMPLETE|\n",
      "|       7|2013-07-25|       4530|       COMPLETE|\n",
      "|       8|2013-07-25|       2911|     PROCESSING|\n",
      "|       9|2013-07-25|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25|       5648|PENDING_PAYMENT|\n",
      "+--------+----------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_column = [\"order_id\",\"order_date\",\"customer_id\",\"order_status\"]\n",
    "df = spark.createDataFrame(ls,order_column)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|2013-07-25|      11599|         CLOSED|\n",
      "|       2|2013-07-25|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|      12111|       COMPLETE|\n",
      "|       4|2013-07-25|       8827|         CLOSED|\n",
      "|       6|2013-07-25|       7130|       COMPLETE|\n",
      "|       7|2013-07-25|       4530|       COMPLETE|\n",
      "|       8|2013-07-25|       2911|     PROCESSING|\n",
      "|       9|2013-07-25|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25|       5648|PENDING_PAYMENT|\n",
      "+--------+----------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_schema = \" order_id int ,order_date string, customer_id int ,order_status string\"\n",
    "df = spark.createDataFrame(ls,order_schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------------+\n",
      "|orderid| orderdate|customerid|    orderstatus|\n",
      "+-------+----------+----------+---------------+\n",
      "|      1|2013-07-25|     11599|         CLOSED|\n",
      "|      2|2013-07-25|       256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25|     12111|       COMPLETE|\n",
      "|      4|2013-07-25|      8827|         CLOSED|\n",
      "|      6|2013-07-25|      7130|       COMPLETE|\n",
      "|      7|2013-07-25|      4530|       COMPLETE|\n",
      "|      8|2013-07-25|      2911|     PROCESSING|\n",
      "|      9|2013-07-25|      5657|PENDING_PAYMENT|\n",
      "|     10|2013-07-25|      5648|PENDING_PAYMENT|\n",
      "+-------+----------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "order_schema = StructType([\n",
    "    StructField(\"orderid\",IntegerType()),\n",
    "    StructField(\"orderdate\",StringType()),\n",
    "    StructField(\"customerid\",IntegerType()),\n",
    "    StructField(\"orderstatus\",StringType())\n",
    "])\n",
    "df = spark.createDataFrame(ls,order_schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderid: integer (nullable = true)\n",
      " |-- orderdate: string (nullable = true)\n",
      " |-- customerid: integer (nullable = true)\n",
      " |-- orderstatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderid: integer (nullable = true)\n",
      " |-- orderdate: date (nullable = true)\n",
      " |-- customerid: integer (nullable = true)\n",
      " |-- orderstatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df_correct = df.withColumn(\"orderdate\",to_date(\"orderdate\",\"yyyy-mm-dd\"))\n",
    "df_correct.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

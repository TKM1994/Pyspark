{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"nested_schema\").getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### schema define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl_schema = \"customer_id long , fullname struct<first_name:string, last_name:string> ,city string\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "struct_schema = StructType([\n",
    "    StructField(\"customer_id\",LongType()),\n",
    "    StructField(\"fullname\",StructType([\n",
    "                                        StructField(\"first_name\",StringType()),\n",
    "                                        StructField(\"last_name\",StringType())\n",
    "                                    ])),\n",
    "    StructField(\"city\",StringType())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### multiline_nested_json_schema_enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "        .schema(ddl_schema) \\\n",
    "            .option(\"multiline\",\"true\") \\\n",
    "                .load(r\"C:\\Users\\TARUN\\Desktop\\Pyspark\\Trendytech\\data\\multiline_nested_json.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+\n",
      "|customer_id|        fullname|     city|\n",
      "+-----------+----------------+---------+\n",
      "|          1|  {tarun, kumar}|bangalore|\n",
      "|          2|  {sumit, kumar}|    delhi|\n",
      "|          3| {manish, kumar}|   mumbai|\n",
      "|          4|{ashwini, kumar}|  chennai|\n",
      "+-----------+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_again = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "        .schema(struct_schema) \\\n",
    "            .option(\"multiline\",\"true\") \\\n",
    "                .load(r\"C:\\Users\\TARUN\\Desktop\\Pyspark\\Trendytech\\data\\multiline_nested_json.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+\n",
      "|customer_id|        fullname|     city|\n",
      "+-----------+----------------+---------+\n",
      "|          1|  {tarun, kumar}|bangalore|\n",
      "|          2|  {sumit, kumar}|    delhi|\n",
      "|          3| {manish, kumar}|   mumbai|\n",
      "|          4|{ashwini, kumar}|  chennai|\n",
      "+-----------+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_again.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_again.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### python_list_nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [\n",
    "    (1,(\"tarun\",\"kumar\"),\"bangalore\"),\n",
    "    (2,(\"sumit\",\"kumar\"),\"delhi\"),\n",
    "    (3,(\"manish\",\"kumar\"),\"mumbai\"),\n",
    "    (4,(\"ashwini\",\"kumar\"),\"chennai\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ls = spark.createDataFrame(customer_list,ddl_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+\n",
      "|customer_id|        fullname|     city|\n",
      "+-----------+----------------+---------+\n",
      "|          1|  {tarun, kumar}|bangalore|\n",
      "|          2|  {sumit, kumar}|    delhi|\n",
      "|          3| {manish, kumar}|   mumbai|\n",
      "|          4|{ashwini, kumar}|  chennai|\n",
      "+-----------+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ls.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ls_struct = spark.createDataFrame(customer_list,struct_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+\n",
      "|customer_id|        fullname|     city|\n",
      "+-----------+----------------+---------+\n",
      "|          1|  {tarun, kumar}|bangalore|\n",
      "|          2|  {sumit, kumar}|    delhi|\n",
      "|          3| {manish, kumar}|   mumbai|\n",
      "|          4|{ashwini, kumar}|  chennai|\n",
      "+-----------+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ls_struct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ls_struct.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### line_delimited_nested_json_schema_enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "        .schema(ddl_schema) \\\n",
    "                .load(r\"C:\\Users\\TARUN\\Desktop\\Pyspark\\Trendytech\\data\\line_delimited_nested_json.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+\n",
      "|customer_id|        fullname|     city|\n",
      "+-----------+----------------+---------+\n",
      "|          1|  {tarun, kumar}|bangalore|\n",
      "|          2|  {sumit, kumar}|    delhi|\n",
      "|          3| {manish, kumar}|   mumbai|\n",
      "|          4|{ashwini, kumar}|  chennai|\n",
      "+-----------+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### line_delimited_nested_with_comma_json_schema_enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "        .schema(ddl_schema) \\\n",
    "                .load(r\"C:\\Users\\TARUN\\Desktop\\Pyspark\\Trendytech\\data\\line_delimited_nested_with_comma.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+\n",
      "|customer_id|        fullname|     city|\n",
      "+-----------+----------------+---------+\n",
      "|          1|  {tarun, kumar}|bangalore|\n",
      "|          2|  {sumit, kumar}|    delhi|\n",
      "|          3| {manish, kumar}|   mumbai|\n",
      "|          4|{ashwini, kumar}|  chennai|\n",
      "+-----------+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### multiline_nested_json_infer_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "        .option(\"inferSchema\",\"true\") \\\n",
    "            .option(\"multiline\",\"true\") \\\n",
    "                .load(r\"C:\\Users\\TARUN\\Desktop\\Pyspark\\Trendytech\\data\\multiline_nested_json.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+\n",
      "|     city|customer_id|        fullname|\n",
      "+---------+-----------+----------------+\n",
      "|bangalore|          1|  {tarun, kumar}|\n",
      "|    delhi|          2|  {sumit, kumar}|\n",
      "|   mumbai|          3| {manish, kumar}|\n",
      "|  chennai|          4|{ashwini, kumar}|\n",
      "+---------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### line_delimited_nested_json_infer_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "        .option(\"inferSchema\",\"true\") \\\n",
    "                .load(r\"C:\\Users\\TARUN\\Desktop\\Pyspark\\Trendytech\\data\\line_delimited_nested_json.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+\n",
      "|     city|customer_id|        fullname|\n",
      "+---------+-----------+----------------+\n",
      "|bangalore|          1|  {tarun, kumar}|\n",
      "|    delhi|          2|  {sumit, kumar}|\n",
      "|   mumbai|          3| {manish, kumar}|\n",
      "|  chennai|          4|{ashwini, kumar}|\n",
      "+---------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### line_delimited_nested_with_comma_json_infer_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "        .option(\"inferSchema\",\"true\") \\\n",
    "                .load(r\"C:\\Users\\TARUN\\Desktop\\Pyspark\\Trendytech\\data\\line_delimited_nested_with_comma.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+\n",
      "|     city|customer_id|        fullname|\n",
      "+---------+-----------+----------------+\n",
      "|bangalore|          1|  {tarun, kumar}|\n",
      "|    delhi|          2|  {sumit, kumar}|\n",
      "|   mumbai|          3| {manish, kumar}|\n",
      "|  chennai|          4|{ashwini, kumar}|\n",
      "+---------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- fullname: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

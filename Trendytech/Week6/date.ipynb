{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"date\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hadoop fs -head  /user/tkm/data/order_wd.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### creating df with inferschema which will consider different date format to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "        .option(\"inferSchema\" ,\"true\") \\\n",
    "        .load(\"hdfs://localhost:9000/user/tkm/data/order_wd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|  07/25/13|      11599|         CLOSED|\n",
      "|       2|  07/25/13|        256|PENDING_PAYMENT|\n",
      "|       3|  07/25/13|      12111|       COMPLETE|\n",
      "|       4|  07/25/13|       8827|         CLOSED|\n",
      "|       5|  07/25/13|      11318|       COMPLETE|\n",
      "+--------+----------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### creating df with schema enforcement but not able to recognise by date format because default format is yyyy-mm-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = 'order_id long , order_date date , customer_id integer , order_status string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "        .schema(orders_schema) \\\n",
    "        .load(\"hdfs://localhost:9000/user/tkm/data/order_wd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|      null|      11599|         CLOSED|\n",
      "|       2|      null|        256|PENDING_PAYMENT|\n",
      "|       3|      null|      12111|       COMPLETE|\n",
      "|       4|      null|       8827|         CLOSED|\n",
      "+--------+----------+-----------+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### creating df with schema enforcement and providing dateformat option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "        .schema(orders_schema) \\\n",
    "        .option(\"dateFormat\" ,\"MM/dd/yy\") \\\n",
    "        .load(\"hdfs://localhost:9000/user/tkm/data/order_wd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|2013-07-25|      11599|         CLOSED|\n",
      "|       2|2013-07-25|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|      12111|       COMPLETE|\n",
      "|       4|2013-07-25|       8827|         CLOSED|\n",
      "+--------+----------+-----------+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### recommended  format first import as string then convert to appropiate format with withcolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = 'order_id long , order_date string , customer_id integer , order_status string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "        .schema(orders_schema) \\\n",
    "        .load(\"hdfs://localhost:9000/user/tkm/data/order_wd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|  07/25/13|      11599|         CLOSED|\n",
      "|       2|  07/25/13|        256|PENDING_PAYMENT|\n",
      "|       3|  07/25/13|      12111|       COMPLETE|\n",
      "|       4|  07/25/13|       8827|         CLOSED|\n",
      "+--------+----------+-----------+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.withColumn(\"order_date\",to_date(\"order_date\" ,\"MM/dd/yy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|   order_status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|2013-07-25|      11599|         CLOSED|\n",
      "|       2|2013-07-25|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|      12111|       COMPLETE|\n",
      "|       4|2013-07-25|       8827|         CLOSED|\n",
      "+--------+----------+-----------+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df4.withColumn(\"order_date_new\",to_date(\"order_date\" ,\"MM/dd/yy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+--------------+\n",
      "|order_id|order_date|customer_id|   order_status|order_date_new|\n",
      "+--------+----------+-----------+---------------+--------------+\n",
      "|       1|  07/25/13|      11599|         CLOSED|    2013-07-25|\n",
      "|       2|  07/25/13|        256|PENDING_PAYMENT|    2013-07-25|\n",
      "|       3|  07/25/13|      12111|       COMPLETE|    2013-07-25|\n",
      "|       4|  07/25/13|       8827|         CLOSED|    2013-07-25|\n",
      "|       5|  07/25/13|      11318|       COMPLETE|    2013-07-25|\n",
      "+--------+----------+-----------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- order_date_new: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

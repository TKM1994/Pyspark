{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"schema_enforcement\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  read data with without header without schema enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"inferSchema\" ,\"true\") \\\n",
    "        .load(\"hdfs://localhost:9000/user/tkm/retail_db/orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+---------------+\n",
      "|_c0|                _c1|  _c2|            _c3|\n",
      "+---+-------------------+-----+---------------+\n",
      "|  1|2013-07-25 00:00:00|11599|         CLOSED|\n",
      "|  2|2013-07-25 00:00:00|  256|PENDING_PAYMENT|\n",
      "|  3|2013-07-25 00:00:00|12111|       COMPLETE|\n",
      "+---+-------------------+-----+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: timestamp (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  read data with without header with schema enforcement normal type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = 'order_id long , order_date timestamp , customer_id integer , order_status string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .schema(orders_schema) \\\n",
    "            .load(\"hdfs://localhost:9000/user/tkm/retail_db/orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  read data with without header with schema enforcement Struct Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing types\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema_structtype = StructType([\n",
    "    StructField(\"orderid\",LongType()),\n",
    "    StructField(\"orderdate\",TimestampType()),\n",
    "    StructField(\"customerid\",IntegerType()),\n",
    "    StructField(\"orderstatus\",StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =  spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .schema(orders_schema_structtype) \\\n",
    "            .load(\"hdfs://localhost:9000/user/tkm/retail_db/orders.csv\")\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------+---------------+\n",
      "|orderid|          orderdate|customerid|    orderstatus|\n",
      "+-------+-------------------+----------+---------------+\n",
      "|      1|2013-07-25 00:00:00|     11599|         CLOSED|\n",
      "|      2|2013-07-25 00:00:00|       256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25 00:00:00|     12111|       COMPLETE|\n",
      "+-------+-------------------+----------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderid: long (nullable = true)\n",
      " |-- orderdate: timestamp (nullable = true)\n",
      " |-- customerid: integer (nullable = true)\n",
      " |-- orderstatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  read data with with header without schema enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "            .option(\"inferSchema\",\"true\")\\\n",
    "                .load(\"hdfs://localhost:9000/user/tkm/data/order.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  read data with with header with schema enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "            .schema(orders_schema)\\\n",
    "                .load(\"hdfs://localhost:9000/user/tkm/data/order.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  different way of selecting column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|order_id|   order_status|\n",
      "+--------+---------------+\n",
      "|       1|         CLOSED|\n",
      "|       2|PENDING_PAYMENT|\n",
      "+--------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select(df5.order_id ,df5.order_status).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|order_id|   order_status|\n",
      "+--------+---------------+\n",
      "|       1|         CLOSED|\n",
      "|       2|PENDING_PAYMENT|\n",
      "+--------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select(\"order_id\",\"order_status\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|order_id|   order_status|\n",
      "+--------+---------------+\n",
      "|       1|         CLOSED|\n",
      "|       2|PENDING_PAYMENT|\n",
      "+--------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select(col(\"order_id\"),col(\"order_status\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id,order_date,customer_id,order_status\n",
      "1,07/25/13,11599,CLOSED\n",
      "2,07/25/13,256,PENDING_PAYMENT\n",
      "3,07/25/13,12111,COMPLETE\n",
      "4,07/25/13,8827,CLOSED\n",
      "5,07/25/13,11318,COMPLETE\n",
      "6,07/25/13,7130,COMPLETE\n",
      "7,07/25/13,4530,COMPLETE\n",
      "8,07/25/13,2911,PROCESSING\n",
      "9,07/25/13,5657,PENDING_PAYMENT\n",
      "10,07/25/13,5648,PENDING_PAYMENT\n",
      "11,07/25/13,918,PAYMENT_REVIEW\n",
      "12,07/25/13,1837,CLOSED\n",
      "13,07/25/13,9149,PENDING_PAYMENT\n",
      "14,07/25/13,9842,PROCESSING\n",
      "15,07/25/13,2568,COMPLETE\n",
      "16,07/25/13,7276,PENDING_PAYMENT\n",
      "17,07/25/13,2667,COMPLETE\n",
      "18,07/25/13,1205,CLOSED\n",
      "19,07/25/13,9488,PENDING_PAYMENT\n",
      "20,07/25/13,9198,PROCESSING\n",
      "21,07/25/13,2711,PENDING\n",
      "22,07/25/13,333,COMPLETE\n",
      "23,07/25/13,4367,PENDING_PAYMENT\n",
      "24,07/25/13,11441,CLOSED\n",
      "25,07/25/13,9503,CLOSED\n",
      "26,07/25/13,7562,COMPLETE\n",
      "27,07/25/13,3241,PENDING_PAYMENT\n",
      "28,07/25/13,656,COMPLETE\n",
      "29,07/25/13,196,PROCESSING\n",
      "30,07/25/13,10039,PENDING_PAYMENT\n",
      "31,07/25/13,6983,PAYMENT_REVIEW\n",
      "32,07/25/13,3960,COMPLETE\n",
      "33,07/25/13,5793,PENDING_PAYMENT\n",
      "34,07/25/13,4189,PR\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -head  /user/tkm/data/order_wd.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"spark_reader\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "            .option(\"inferSchema\",\"true\") \\\n",
    "                .load(\"hdfs://localhost:9000/user/tkm/data/orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+--------+\n",
      "|_c0|order_id|      date|customer_id|  status|\n",
      "+---+--------+----------+-----------+--------+\n",
      "|  0|       1|09/11/2020|       3371|  CLOSED|\n",
      "|  1|       2|12/01/2020|       3902| PENDING|\n",
      "|  2|       3|12/09/2020|       3009|COMPLETE|\n",
      "|  3|       4|22/08/2020|       3023| PENDING|\n",
      "|  4|       5|17/04/2020|       4315| PENDING|\n",
      "|  5|       6|24/12/2020|       3462|COMPLETE|\n",
      "|  6|       7|04/04/2020|       3248| PENDING|\n",
      "|  7|       8|13/06/2020|       4434|  CLOSED|\n",
      "|  8|       9|14/02/2020|       4580|COMPLETE|\n",
      "|  9|      10|22/06/2020|       3295|COMPLETE|\n",
      "| 10|      11|18/03/2020|       3786|COMPLETE|\n",
      "| 11|      12|04/08/2020|       3743| PENDING|\n",
      "| 12|      13|18/04/2020|       4555|  CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|  CLOSED|\n",
      "| 14|      15|08/05/2020|       3042|COMPLETE|\n",
      "| 15|      16|04/12/2020|       3980|  CLOSED|\n",
      "| 16|      17|07/06/2020|       4189| PENDING|\n",
      "| 17|      18|15/02/2020|       3271|COMPLETE|\n",
      "| 18|      19|02/08/2020|       3669| PENDING|\n",
      "| 19|      20|18/02/2020|       4251| PENDING|\n",
      "+---+--------+----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+--------+\n",
      "|_c0|order_id|      date|customer_id|  status|\n",
      "+---+--------+----------+-----------+--------+\n",
      "|  0|       1|09/11/2020|       3371|  CLOSED|\n",
      "|  1|       2|12/01/2020|       3902| PENDING|\n",
      "|  2|       3|12/09/2020|       3009|COMPLETE|\n",
      "|  3|       4|22/08/2020|       3023| PENDING|\n",
      "|  4|       5|17/04/2020|       4315| PENDING|\n",
      "|  5|       6|24/12/2020|       3462|COMPLETE|\n",
      "|  6|       7|04/04/2020|       3248| PENDING|\n",
      "|  7|       8|13/06/2020|       4434|  CLOSED|\n",
      "|  8|       9|14/02/2020|       4580|COMPLETE|\n",
      "|  9|      10|22/06/2020|       3295|COMPLETE|\n",
      "| 10|      11|18/03/2020|       3786|COMPLETE|\n",
      "| 11|      12|04/08/2020|       3743| PENDING|\n",
      "| 12|      13|18/04/2020|       4555|  CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|  CLOSED|\n",
      "| 14|      15|08/05/2020|       3042|COMPLETE|\n",
      "| 15|      16|04/12/2020|       3980|  CLOSED|\n",
      "| 16|      17|07/06/2020|       4189| PENDING|\n",
      "| 17|      18|15/02/2020|       3271|COMPLETE|\n",
      "| 18|      19|02/08/2020|       3669| PENDING|\n",
      "| 19|      20|18/02/2020|       4251| PENDING|\n",
      "+---+--------+----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv(\"hdfs://localhost:9000/user/tkm/data/orders.csv\",header = \"true\",inferSchema=\"True\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.withColumnRenamed(\"_c0\",\"row_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- row_number: integer (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----------+--------+\n",
      "|row_number|order_id|      date|customer_id|  status|\n",
      "+----------+--------+----------+-----------+--------+\n",
      "|         0|       1|09/11/2020|       3371|  CLOSED|\n",
      "|         1|       2|12/01/2020|       3902| PENDING|\n",
      "|         2|       3|12/09/2020|       3009|COMPLETE|\n",
      "|         3|       4|22/08/2020|       3023| PENDING|\n",
      "+----------+--------+----------+-----------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+--------+\n",
      "|_c0|order_id|      date|customer_id|  status|\n",
      "+---+--------+----------+-----------+--------+\n",
      "|  0|       1|09/11/2020|       3371|  CLOSED|\n",
      "|  1|       2|12/01/2020|       3902| PENDING|\n",
      "|  2|       3|12/09/2020|       3009|COMPLETE|\n",
      "|  3|       4|22/08/2020|       3023| PENDING|\n",
      "|  4|       5|17/04/2020|       4315| PENDING|\n",
      "|  5|       6|24/12/2020|       3462|COMPLETE|\n",
      "|  6|       7|04/04/2020|       3248| PENDING|\n",
      "|  7|       8|13/06/2020|       4434|  CLOSED|\n",
      "|  8|       9|14/02/2020|       4580|COMPLETE|\n",
      "|  9|      10|22/06/2020|       3295|COMPLETE|\n",
      "| 10|      11|18/03/2020|       3786|COMPLETE|\n",
      "| 11|      12|04/08/2020|       3743| PENDING|\n",
      "| 12|      13|18/04/2020|       4555|  CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|  CLOSED|\n",
      "| 14|      15|08/05/2020|       3042|COMPLETE|\n",
      "| 15|      16|04/12/2020|       3980|  CLOSED|\n",
      "| 16|      17|07/06/2020|       4189| PENDING|\n",
      "| 17|      18|15/02/2020|       3271|COMPLETE|\n",
      "| 18|      19|02/08/2020|       3669| PENDING|\n",
      "| 19|      20|18/02/2020|       4251| PENDING|\n",
      "+---+--------+----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "|age|    name|salary|\n",
      "+---+--------+------+\n",
      "| 20|  Manish| 20000|\n",
      "| 25|  Nikita| 21000|\n",
      "| 16|  Pritam| 22000|\n",
      "| 35|Prantosh| 25000|\n",
      "| 67|  Vikash| 40000|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"json\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "        .option(\"mode\",\"PERMISSIVE\")\\\n",
    "            .load(\"C:\\\\Users\\\\TARUN\\\\Desktop\\\\Pyspark\\\\manish\\\\line_delimited_json.json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "|age|    name|salary|\n",
      "+---+--------+------+\n",
      "| 20|  Manish| 20000|\n",
      "| 25|  Nikita| 21000|\n",
      "| 16|  Pritam| 22000|\n",
      "| 35|Prantosh| 25000|\n",
      "| 67|  Vikash| 40000|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"json\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "        .option(\"mode\",\"PERMISSIVE\")\\\n",
    "            .option(\"multiline\",\"true\")\\\n",
    "            .load(\"C:\\\\Users\\\\TARUN\\\\Desktop\\\\Pyspark\\\\manish\\\\Multi_line_correct.json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+------+\n",
      "|age|               group|  name|salary|\n",
      "+---+--------------------+------+------+\n",
      "| 20|[{20, Manish, 200...|Manish| 20000|\n",
      "+---+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"json\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "        .option(\"mode\",\"PERMISSIVE\")\\\n",
    "            .option(\"multiline\",\"true\")\\\n",
    "            .load(\"C:\\\\Users\\\\TARUN\\\\Desktop\\\\Pyspark\\\\manish\\\\experiment.json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------+--------+\n",
      "|customer_id|      date|order_id|row_number|  status|\n",
      "+-----------+----------+--------+----------+--------+\n",
      "|       3371|09/11/2020|       1|         0|  CLOSED|\n",
      "|       3902|12/01/2020|       2|         1| PENDING|\n",
      "|       3009|12/09/2020|       3|         2|COMPLETE|\n",
      "|       3023|22/08/2020|       4|         3| PENDING|\n",
      "|       4315|17/04/2020|       5|         4| PENDING|\n",
      "|       3462|24/12/2020|       6|         5|COMPLETE|\n",
      "|       3248|04/04/2020|       7|         6| PENDING|\n",
      "|       4434|13/06/2020|       8|         7|  CLOSED|\n",
      "|       4580|14/02/2020|       9|         8|COMPLETE|\n",
      "|       3295|22/06/2020|      10|         9|COMPLETE|\n",
      "|       3786|18/03/2020|      11|        10|COMPLETE|\n",
      "|       3743|04/08/2020|      12|        11| PENDING|\n",
      "|       4555|18/04/2020|      13|        12|  CLOSED|\n",
      "|       3069|30/04/2020|      14|        13|  CLOSED|\n",
      "|       3042|08/05/2020|      15|        14|COMPLETE|\n",
      "|       3980|04/12/2020|      16|        15|  CLOSED|\n",
      "|       4189|07/06/2020|      17|        16| PENDING|\n",
      "|       3271|15/02/2020|      18|        17|COMPLETE|\n",
      "|       3669|02/08/2020|      19|        18| PENDING|\n",
      "|       4251|18/02/2020|      20|        19| PENDING|\n",
      "+-----------+----------+--------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"json\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "        .option(\"mode\",\"PERMISSIVE\")\\\n",
    "            .option(\"multiline\",\"true\")\\\n",
    "            .load(\"C:\\\\Users\\\\TARUN\\\\Desktop\\\\Pyspark\\\\order\\\\order.json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------+--------+\n",
      "|customer_id|      date|order_id|row_number|  status|\n",
      "+-----------+----------+--------+----------+--------+\n",
      "|       3371|09/11/2020|       1|         0|  CLOSED|\n",
      "|       3902|12/01/2020|       2|         1| PENDING|\n",
      "|       3009|12/09/2020|       3|         2|COMPLETE|\n",
      "|       3023|22/08/2020|       4|         3| PENDING|\n",
      "|       4315|17/04/2020|       5|         4| PENDING|\n",
      "|       3462|24/12/2020|       6|         5|COMPLETE|\n",
      "|       3248|04/04/2020|       7|         6| PENDING|\n",
      "|       4434|13/06/2020|       8|         7|  CLOSED|\n",
      "|       4580|14/02/2020|       9|         8|COMPLETE|\n",
      "|       3295|22/06/2020|      10|         9|COMPLETE|\n",
      "|       3786|18/03/2020|      11|        10|COMPLETE|\n",
      "|       3743|04/08/2020|      12|        11| PENDING|\n",
      "|       4555|18/04/2020|      13|        12|  CLOSED|\n",
      "|       3069|30/04/2020|      14|        13|  CLOSED|\n",
      "|       3042|08/05/2020|      15|        14|COMPLETE|\n",
      "|       3980|04/12/2020|      16|        15|  CLOSED|\n",
      "|       4189|07/06/2020|      17|        16| PENDING|\n",
      "|       3271|15/02/2020|      18|        17|COMPLETE|\n",
      "|       3669|02/08/2020|      19|        18| PENDING|\n",
      "|       4251|18/02/2020|      20|        19| PENDING|\n",
      "+-----------+----------+--------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"json\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "        .option(\"mode\",\"PERMISSIVE\")\\\n",
    "            .option(\"multiline\",\"true\")\\\n",
    "            .load(\"hdfs://localhost:9000/user/tkm/data/order.json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "|age|    name|salary|\n",
      "+---+--------+------+\n",
      "| 20|  Manish| 20000|\n",
      "| 25|  Nikita| 21000|\n",
      "| 16|  Pritam| 22000|\n",
      "| 35|Prantosh| 25000|\n",
      "| 67|  Vikash| 40000|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# shortcut should not be used it will only work for line_delimited_json\n",
    "spark.read.json(\"C:\\\\Users\\\\TARUN\\\\Desktop\\\\Pyspark\\\\manish\\\\line_delimited_json.json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_json_df = spark.read.format(\"json\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "        .option(\"mode\",\"PERMISSIVE\")\\\n",
    "            .option(\"multiline\",\"true\")\\\n",
    "            .load(\"hdfs://localhost:9000/user/tkm/data/order.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- row_number: long (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------+--------+\n",
      "|customer_id|      date|order_id|row_number|  status|\n",
      "+-----------+----------+--------+----------+--------+\n",
      "|       3371|09/11/2020|       1|         0|  CLOSED|\n",
      "|       3902|12/01/2020|       2|         1| PENDING|\n",
      "|       3009|12/09/2020|       3|         2|COMPLETE|\n",
      "|       3023|22/08/2020|       4|         3| PENDING|\n",
      "|       4315|17/04/2020|       5|         4| PENDING|\n",
      "|       3462|24/12/2020|       6|         5|COMPLETE|\n",
      "|       3248|04/04/2020|       7|         6| PENDING|\n",
      "|       4434|13/06/2020|       8|         7|  CLOSED|\n",
      "|       4580|14/02/2020|       9|         8|COMPLETE|\n",
      "|       3295|22/06/2020|      10|         9|COMPLETE|\n",
      "|       3786|18/03/2020|      11|        10|COMPLETE|\n",
      "|       3743|04/08/2020|      12|        11| PENDING|\n",
      "|       4555|18/04/2020|      13|        12|  CLOSED|\n",
      "|       3069|30/04/2020|      14|        13|  CLOSED|\n",
      "|       3042|08/05/2020|      15|        14|COMPLETE|\n",
      "|       3980|04/12/2020|      16|        15|  CLOSED|\n",
      "|       4189|07/06/2020|      17|        16| PENDING|\n",
      "|       3271|15/02/2020|      18|        17|COMPLETE|\n",
      "|       3669|02/08/2020|      19|        18| PENDING|\n",
      "|       4251|18/02/2020|      20|        19| PENDING|\n",
      "+-----------+----------+--------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.json(\"hdfs://localhost:9000/user/tkm/data/order.json\" , multiLine = \"true\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+-----------+--------+\n",
      "|column0|order_id|      date|customer_id|  status|\n",
      "+-------+--------+----------+-----------+--------+\n",
      "|      0|       1|2020-11-09|       3371|  CLOSED|\n",
      "|      1|       2|2020-01-12|       3902| PENDING|\n",
      "|      2|       3|2020-09-12|       3009|COMPLETE|\n",
      "|      3|       4|2020-08-22|       3023| PENDING|\n",
      "|      4|       5|2020-04-17|       4315| PENDING|\n",
      "|      5|       6|2020-12-24|       3462|COMPLETE|\n",
      "|      6|       7|2020-04-04|       3248| PENDING|\n",
      "|      7|       8|2020-06-13|       4434|  CLOSED|\n",
      "|      8|       9|2020-02-14|       4580|COMPLETE|\n",
      "|      9|      10|2020-06-22|       3295|COMPLETE|\n",
      "|     10|      11|2020-03-18|       3786|COMPLETE|\n",
      "|     11|      12|2020-08-04|       3743| PENDING|\n",
      "|     12|      13|2020-04-18|       4555|  CLOSED|\n",
      "|     13|      14|2020-04-30|       3069|  CLOSED|\n",
      "|     14|      15|2020-05-08|       3042|COMPLETE|\n",
      "|     15|      16|2020-12-04|       3980|  CLOSED|\n",
      "|     16|      17|2020-06-07|       4189| PENDING|\n",
      "|     17|      18|2020-02-15|       3271|COMPLETE|\n",
      "|     18|      19|2020-08-02|       3669| PENDING|\n",
      "|     19|      20|2020-02-18|       4251| PENDING|\n",
      "+-------+--------+----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"C:\\\\Users\\\\TARUN\\\\Desktop\\\\Pyspark\\\\order\\\\orders.parquet\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Charlie| 35|\n",
      "|  Alice| 25|\n",
      "|    Bob| 30|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.orc(\"C:\\\\Users\\\\TARUN\\\\Desktop\\\\Pyspark\\\\order\\\\orc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+-------+\n",
      "|_c0|order_id|      date|customer_id| status|\n",
      "+---+--------+----------+-----------+-------+\n",
      "|  0|       1|09/11/2020|       3371| CLOSED|\n",
      "|  1|       2|12/01/2020|       3902|PENDING|\n",
      "+---+--------+----------+-----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+------+\n",
      "|_c0|order_id|      date|customer_id|status|\n",
      "+---+--------+----------+-----------+------+\n",
      "|  0|       1|09/11/2020|       3371|CLOSED|\n",
      "|  7|       8|13/06/2020|       4434|CLOSED|\n",
      "| 12|      13|18/04/2020|       4555|CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|CLOSED|\n",
      "| 15|      16|04/12/2020|       3980|CLOSED|\n",
      "| 21|      22|11/10/2020|       3700|CLOSED|\n",
      "| 22|      23|26/01/2020|       4796|CLOSED|\n",
      "| 26|      27|07/04/2020|       4990|CLOSED|\n",
      "| 29|      30|28/02/2020|       3408|CLOSED|\n",
      "| 31|      32|08/11/2020|       4463|CLOSED|\n",
      "| 32|      33|03/05/2020|       3456|CLOSED|\n",
      "| 34|      35|24/03/2020|       4669|CLOSED|\n",
      "| 36|      37|07/08/2020|       4007|CLOSED|\n",
      "| 37|      38|19/08/2020|       4187|CLOSED|\n",
      "| 38|      39|19/02/2020|       4372|CLOSED|\n",
      "| 40|      41|27/01/2020|       4416|CLOSED|\n",
      "| 41|      42|14/11/2020|       3251|CLOSED|\n",
      "| 46|      47|07/06/2020|       3817|CLOSED|\n",
      "| 48|      49|19/11/2020|       4760|CLOSED|\n",
      "| 50|      51|27/07/2020|       4299|CLOSED|\n",
      "+---+--------+----------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.where(df1.status == \"CLOSED\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+------+\n",
      "|_c0|order_id|      date|customer_id|status|\n",
      "+---+--------+----------+-----------+------+\n",
      "|  0|       1|09/11/2020|       3371|CLOSED|\n",
      "|  7|       8|13/06/2020|       4434|CLOSED|\n",
      "| 12|      13|18/04/2020|       4555|CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|CLOSED|\n",
      "| 15|      16|04/12/2020|       3980|CLOSED|\n",
      "| 21|      22|11/10/2020|       3700|CLOSED|\n",
      "| 22|      23|26/01/2020|       4796|CLOSED|\n",
      "| 26|      27|07/04/2020|       4990|CLOSED|\n",
      "| 29|      30|28/02/2020|       3408|CLOSED|\n",
      "| 31|      32|08/11/2020|       4463|CLOSED|\n",
      "| 32|      33|03/05/2020|       3456|CLOSED|\n",
      "| 34|      35|24/03/2020|       4669|CLOSED|\n",
      "| 36|      37|07/08/2020|       4007|CLOSED|\n",
      "| 37|      38|19/08/2020|       4187|CLOSED|\n",
      "| 38|      39|19/02/2020|       4372|CLOSED|\n",
      "| 40|      41|27/01/2020|       4416|CLOSED|\n",
      "| 41|      42|14/11/2020|       3251|CLOSED|\n",
      "| 46|      47|07/06/2020|       3817|CLOSED|\n",
      "| 48|      49|19/11/2020|       4760|CLOSED|\n",
      "| 50|      51|27/07/2020|       4299|CLOSED|\n",
      "+---+--------+----------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(df1.status == \"CLOSED\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+------+\n",
      "|_c0|order_id|      date|customer_id|status|\n",
      "+---+--------+----------+-----------+------+\n",
      "|  0|       1|09/11/2020|       3371|CLOSED|\n",
      "|  7|       8|13/06/2020|       4434|CLOSED|\n",
      "| 12|      13|18/04/2020|       4555|CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|CLOSED|\n",
      "| 15|      16|04/12/2020|       3980|CLOSED|\n",
      "| 21|      22|11/10/2020|       3700|CLOSED|\n",
      "| 22|      23|26/01/2020|       4796|CLOSED|\n",
      "| 26|      27|07/04/2020|       4990|CLOSED|\n",
      "| 29|      30|28/02/2020|       3408|CLOSED|\n",
      "| 31|      32|08/11/2020|       4463|CLOSED|\n",
      "| 32|      33|03/05/2020|       3456|CLOSED|\n",
      "| 34|      35|24/03/2020|       4669|CLOSED|\n",
      "| 36|      37|07/08/2020|       4007|CLOSED|\n",
      "| 37|      38|19/08/2020|       4187|CLOSED|\n",
      "| 38|      39|19/02/2020|       4372|CLOSED|\n",
      "| 40|      41|27/01/2020|       4416|CLOSED|\n",
      "| 41|      42|14/11/2020|       3251|CLOSED|\n",
      "| 46|      47|07/06/2020|       3817|CLOSED|\n",
      "| 48|      49|19/11/2020|       4760|CLOSED|\n",
      "| 50|      51|27/07/2020|       4299|CLOSED|\n",
      "+---+--------+----------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.where(col(\"status\") == \"CLOSED\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"df1_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+------+\n",
      "|_c0|order_id|      date|customer_id|status|\n",
      "+---+--------+----------+-----------+------+\n",
      "|  0|       1|09/11/2020|       3371|CLOSED|\n",
      "|  7|       8|13/06/2020|       4434|CLOSED|\n",
      "| 12|      13|18/04/2020|       4555|CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|CLOSED|\n",
      "| 15|      16|04/12/2020|       3980|CLOSED|\n",
      "| 21|      22|11/10/2020|       3700|CLOSED|\n",
      "| 22|      23|26/01/2020|       4796|CLOSED|\n",
      "| 26|      27|07/04/2020|       4990|CLOSED|\n",
      "| 29|      30|28/02/2020|       3408|CLOSED|\n",
      "| 31|      32|08/11/2020|       4463|CLOSED|\n",
      "| 32|      33|03/05/2020|       3456|CLOSED|\n",
      "| 34|      35|24/03/2020|       4669|CLOSED|\n",
      "| 36|      37|07/08/2020|       4007|CLOSED|\n",
      "| 37|      38|19/08/2020|       4187|CLOSED|\n",
      "| 38|      39|19/02/2020|       4372|CLOSED|\n",
      "| 40|      41|27/01/2020|       4416|CLOSED|\n",
      "| 41|      42|14/11/2020|       3251|CLOSED|\n",
      "| 46|      47|07/06/2020|       3817|CLOSED|\n",
      "| 48|      49|19/11/2020|       4760|CLOSED|\n",
      "| 50|      51|27/07/2020|       4299|CLOSED|\n",
      "+---+--------+----------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df1_table where status = 'CLOSED'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ty=spark.read.table(\"df1_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+--------+\n",
      "|_c0|order_id|      date|customer_id|  status|\n",
      "+---+--------+----------+-----------+--------+\n",
      "|  0|       1|09/11/2020|       3371|  CLOSED|\n",
      "|  1|       2|12/01/2020|       3902| PENDING|\n",
      "|  2|       3|12/09/2020|       3009|COMPLETE|\n",
      "|  3|       4|22/08/2020|       3023| PENDING|\n",
      "|  4|       5|17/04/2020|       4315| PENDING|\n",
      "|  5|       6|24/12/2020|       3462|COMPLETE|\n",
      "|  6|       7|04/04/2020|       3248| PENDING|\n",
      "|  7|       8|13/06/2020|       4434|  CLOSED|\n",
      "|  8|       9|14/02/2020|       4580|COMPLETE|\n",
      "|  9|      10|22/06/2020|       3295|COMPLETE|\n",
      "| 10|      11|18/03/2020|       3786|COMPLETE|\n",
      "| 11|      12|04/08/2020|       3743| PENDING|\n",
      "| 12|      13|18/04/2020|       4555|  CLOSED|\n",
      "| 13|      14|30/04/2020|       3069|  CLOSED|\n",
      "| 14|      15|08/05/2020|       3042|COMPLETE|\n",
      "| 15|      16|04/12/2020|       3980|  CLOSED|\n",
      "| 16|      17|07/06/2020|       4189| PENDING|\n",
      "| 17|      18|15/02/2020|       3271|COMPLETE|\n",
      "| 18|      19|02/08/2020|       3669| PENDING|\n",
      "| 19|      20|18/02/2020|       4251| PENDING|\n",
      "+---+--------+----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ty.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|   sample|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database if not exists sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|   sample|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").filter(\" namespace = 'sample' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |df1_table|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
